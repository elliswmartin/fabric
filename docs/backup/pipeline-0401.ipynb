{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base data sci libraries\n",
    "import os\n",
    "import pywt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import gabor_kernel\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "from scipy.stats import moment\n",
    "\n",
    "# image processing libraries\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "\n",
    "# sklearn for pipeline creation and grid-search cv\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# BELOW ONLY NEEDED IF WE GO WITH THE IMPLEMENTATION OF A CNN, BUT I THINK THAT WOULD BE OVER THE TOP FOR THIS TASK\n",
    "# ! pip install tensorflow\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "np.random.seed(23)\n",
    "plt.rcParams['figure.figsize'] = (4, 4)\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To-Dos\n",
    "* Run PCA on existing features \n",
    "* Finalize feature selections & tune features\n",
    "* Once we have features, tweak and play with the grid-search CV to get some baseline results for our model\n",
    "* Pickle the feature df\n",
    "\n",
    "### Done\n",
    "* Add feature functions into cell with extract_log_features() mimicking the format and the instructions there\n",
    "* Update parse_data() to include any features generated from the functions defined in the featurize block\n",
    "* Add PCA and any other data exploration we want to complete for feature selection\n",
    "* Decide on strategy in terms of flattening images or using scalar features -- what is worth spending computational umph on based on data exploration? - NO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURIZE\n",
    "\n",
    "We need to translate the features we have already created + those in the proposal + those in the dataset paper into features that are either scalars to be appended to the image vector or a vector of features that can be concatenated onto the end of the feature vector.\n",
    "\n",
    "Below I have created a formula which defaults to producing a scalar representation of the Laplacian of Gaussian filter. You could also run the filter across the image and then flatten the resulting LoG filtered matrix into a vector (more computationally intensive). This function can be used as a template for the development of other feature formulae to be included in the df creation in the parse_data() function.\n",
    "\n",
    "##### ERIN TO DO - remember how to use pandas pipeline so we can pass these functions as arguments into parse_data() instead of entering them manually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_log_features(image_array, sigma=0.7, scalar=True):\n",
    "    \"\"\"\n",
    "    Extract Laplacian of Gaussian (LoG) features from an image array.\n",
    "    \n",
    "    Parameters:\n",
    "        image_array (numpy.ndarray): The input image array.\n",
    "        sigma (float): The sigma value for the Gaussian filter. Controls the amount of smoothing.\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: The LoG filtered image as a feature vector.\n",
    "    \"\"\"\n",
    "    # apply Laplacian of Gaussian filter\n",
    "    log_image = ndimage.gaussian_laplace(image_array, sigma=sigma)\n",
    "\n",
    "    if scalar:\n",
    "        \n",
    "        # OPTION 1\n",
    "        \n",
    "        # feature scalar: the sum of absolute values in the LoG image (a simple measure of edginess)\n",
    "        feature_scalar = np.sum(np.abs(log_image))\n",
    "\n",
    "        return feature_scalar\n",
    "\n",
    "    else:\n",
    "        # OPTION 2\n",
    "        \n",
    "        # feature vector: flatten the LoG image to use as a feature vector directly\n",
    "        feature_vector = log_image.flatten()\n",
    "\n",
    "        return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Adjusted HOG so we could return other scalar stats in addition to mean if we want to \n",
    "def extract_hog_features(image_array, orientation, pixels, scalar=True):\n",
    "    \"\"\"\n",
    "    Extract HOG features from an image array.\n",
    "    \n",
    "    Parameters:\n",
    "        image_array (numpy.ndarray): The input image array.\n",
    "        saclar: if the output must be a scalar or a feature vector\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: The HOG as a list of scalars or a feature vector.\n",
    "    \"\"\"\n",
    "    #preprocessing\n",
    "    # convert to floating point image with intensity [0, 1]\n",
    "    if np.max(image_array) > 1:\n",
    "        img = image_array.astype(np.float32) / 255.0\n",
    "    # convert to grayscale\n",
    "    if len(img.shape) > 2:\n",
    "        img = rgb2gray(img)\n",
    "    gray_img = img\n",
    "    #HOG feature extraction\n",
    "    #the orientation and pixels will increase the detail (more orientations and less pixels are more computationally expensive)\n",
    "    feature_vector = hog(gray_img, orientations=orientation, pixels_per_cell=(pixels, pixels), visualize=False, feature_vector=True)  \n",
    "    if scalar:\n",
    "        feature_scalar_ls = []\n",
    "        feature_scalar_ls.extend([np.mean(feature_vector), #np.mean is for averaging features\n",
    "                               np.sum(feature_vector), # Overall \"strength\" or \"intensity\" of the features\n",
    "                               np.var(feature_vector),  # Variance\n",
    "                               moment(feature_vector, moment=3), # Skewness\n",
    "                               moment(feature_vector, moment=4)]) # Kurtosis\n",
    "                \n",
    "        return feature_scalar_ls\n",
    "    else:\n",
    "        return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_normals_features(image_array, scalar=True):\n",
    "    #preprocessing\n",
    "    # convert to floating point image with intensity [0, 1]\n",
    "    if np.max(image_array) > 1:\n",
    "        img = image_array.astype(np.float32) / 255.0\n",
    "    # convert to grayscale\n",
    "    if len(img.shape) > 2:\n",
    "        img = rgb2gray(img)\n",
    "    gray_img = img\n",
    "    # Compute gradients using Sobel operator\n",
    "    sobel_x = cv2.Sobel(gray_img, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(gray_img, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "    # Compute normal vectors Nx, Ny, Nz\n",
    "    norm = np.sqrt(sobel_x**2 + sobel_y**2 + 1e-6)\n",
    "    nx = sobel_x / norm\n",
    "    ny = sobel_y / norm\n",
    "    nz = 1 / norm\n",
    "\n",
    "    # Concatenate nx, ny, nz along a new axis, and flatten it to form a 1D feature vector\n",
    "    feature_vector = np.stack((nx, ny, nz), axis=-1).reshape(-1)\n",
    "    if scalar:\n",
    "        feature_scalar = np.sum(feature_vector)\n",
    "        return feature_scalar\n",
    "    else:\n",
    "        return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More on Gabor: https://medium.com/@anuj_shah/through-the-eyes-of-gabor-filter-17d1fdb3ac97\n",
    "\n",
    "def extract_gabor_features(image_array, frequency=0.6, theta=0, sigma=1.0, scalar=True):\n",
    "    \"\"\"\n",
    "    Extract Gabor features from an image array.\n",
    "\n",
    "    Parameters:\n",
    "        image_array (numpy.ndarray): Input image array.\n",
    "        frequency (float): Controls width of strips of Gabor function. Decreasing wavelength produces thinner stripes\n",
    "        theta (float): Orientation of the Gabor kernel in radians.\n",
    "        sigma (float): Standard deviation of kernel in both x and y directions (isotropic).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Gabor-filtered image as a feature (scalar or vector).\n",
    "    \"\"\"\n",
    "    # Create Gabor kernel\n",
    "    kernel = np.real(gabor_kernel(frequency, theta=theta, sigma_x=sigma, sigma_y=sigma)) # NOTE: Adjust sigma_x or sigma_y if want anisotropic\n",
    "\n",
    "    # Apply Gabor kernel to image\n",
    "    gabor_image = np.abs(ndimage.convolve(image_array, kernel, mode='wrap'))\n",
    "\n",
    "    if scalar:\n",
    "        # OPTION 1\n",
    "        # Feature scalar: sum of values in Gabor filtered image\n",
    "        feature_scalar = np.sum(gabor_image)\n",
    "        return feature_scalar\n",
    "    else:\n",
    "        # OPTION 2\n",
    "        # Feature vector: flatten Gabor filtered image to use as feature vector directly\n",
    "        feature_vector = gabor_image.flatten()\n",
    "        return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More on BoVW: https://rlrocha.medium.com/bag-of-visual-words-applied-to-image-classification-64a7de0b6369\n",
    "# And Pyramid Histogram of Visual Words: https://slazebni.cs.illinois.edu/publications/pyramid_chapter.pdf\n",
    "\n",
    "def extract_bovw_features(image_array, n_clusters=5, scalar=True):    \n",
    "    \"\"\"\n",
    "    Extract Bag of Visual Words (BoVW) features from an image array.\n",
    "\n",
    "    Parameters:\n",
    "    image_array (numpy.ndarray): Input image array.\n",
    "    codebook (numpy.ndarray): Visual vocabulary for quantization.\n",
    "    patch_size (tuple): Size of the image patches to extract (height, width).\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: BoVW representation as a feature (scalar or vector).\n",
    "    \"\"\"\n",
    "    # Detect and compute local features w/ SIFT\n",
    "    \n",
    "    detector = cv2.SIFT_create()\n",
    "    keypoints, descriptors = detector.detectAndCompute(image_array, None)\n",
    "\n",
    "    if descriptors is None:\n",
    "        # Handle case when no keypoints are detected\n",
    "        if scalar:\n",
    "            return 0\n",
    "        else:\n",
    "            return np.zeros(n_clusters)\n",
    "\n",
    "    # Create visual vocabulary (codebook)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    kmeans.fit(descriptors)\n",
    "    codebook = kmeans.cluster_centers_\n",
    "\n",
    "    # Quantize local features to nearest visual word\n",
    "    labels = kmeans.predict(descriptors)\n",
    "\n",
    "    # Create BoVW histogram\n",
    "    bovw_hist, _ = np.histogram(labels, bins=np.arange(n_clusters + 1), density=True)\n",
    "\n",
    "    if scalar:\n",
    "        # OPTION 1\n",
    "        # Feature scalar: sum of values in the BoVW histogram\n",
    "        feature_scalar = np.sum(bovw_hist)\n",
    "        return feature_scalar\n",
    "    else:\n",
    "        # OPTION 2\n",
    "        # Feature vector: BoVW histogram\n",
    "        feature_vector = bovw_hist\n",
    "        return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More on Wavelet: https://medium.com/@shouke.wei/basic-concepts-of-wavelets-transform-43830a68ac34\n",
    "\n",
    "def extract_wavelet_features(image_array, wavelet='haar', level=1, scalar=True):\n",
    "    \"\"\"\n",
    "    Extract wavelet transform features from image array.\n",
    "    \n",
    "    Parameters:\n",
    "        image_array (numpy.ndarray): Input image array.\n",
    "        wavelet (str): Type of wavelet to be used. \n",
    "            Doc: https://pywavelets.readthedocs.io/en/latest/ref/wavelets.html\n",
    "            And: https://pywavelets.readthedocs.io/en/latest/regression/wavelet.html\n",
    "        level (int): Level of decomposition in wavelet transform.\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Wavelet feature as a vector or scalar.\n",
    "    \"\"\"\n",
    "    # apply wavelet transform\n",
    "    coeffs = pywt.wavedec2(image_array, wavelet, level=level)\n",
    "\n",
    "    if scalar:\n",
    "        # compute mean, variance, skewness, and kurtosis from wavelet coefficients\n",
    "        cA, cD = coeffs[0], coeffs[1:]\n",
    "        feature_scalar_ls = []\n",
    "        feature_scalar_ls.extend([np.mean(cA), np.var(cA), np.mean(cD), np.var(cD)])\n",
    "        \n",
    "\n",
    "        return feature_scalar_ls\n",
    "    else:\n",
    "        # return wavelet coefficients as a flattened feature vector\n",
    "        feature_vector = np.concatenate([c.flatten() for c in coeffs])\n",
    "        return feature_vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In essence, each image needs to be represented as a feature vector. In the D200 example, the photos of the clothing items were in grayscale and then normalized and then reshaped using `train_images_vectors = np.reshape(train_images, (len(train_images), -1))` where train images is an array of n 28 x 28 training images (i.e. train_images.shape = (n, 28, 28)). After each image is reshaped, the vector is 1 x 784 (i.e. 28 x 28).\n",
    "\n",
    "We need a dataframe at the end of the day, where each row represents an image and its features. I want to talk more about which features we are actually going to leverage and use as a team, but for right now, I will build the plumbing to be able to run a classification once we actually have the features using the 'full image' technique employed in D200. In our case the images are still 200 x 200."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Data to DF + Add In Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(folder_path):\n",
    "    image_vectors = []  # image data\n",
    "    labels = []  # labels\n",
    "    ids = []  # unique IDs\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".png\"):\n",
    "            parts = filename.split('_')\n",
    "            fabType = parts[0]\n",
    "            id1 = parts[1]\n",
    "            id2 = parts[3].split('.')[0]  # Remove .png extension\n",
    "            \n",
    "            unique_id = id1 + id2\n",
    "\n",
    "            img = Image.open(os.path.join(folder_path, filename)).convert('L')\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            # normalize the image vector to be between 0 and 1\n",
    "            img_vector_normalized = img_array.flatten() / 255.0\n",
    "            \n",
    "            image_vectors.append(img_vector_normalized)\n",
    "            labels.append(fabType)\n",
    "            ids.append(unique_id)\n",
    "\n",
    "    X = np.array(image_vectors)\n",
    "    Y = np.array(labels)\n",
    "    unique_ids = np.array(ids)\n",
    "    return X, Y, unique_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_all(folder_path):\n",
    "    image_vectors = []  # image data\n",
    "    labels = []  # labels\n",
    "    ids = []  # unique IDs\n",
    "    features = []\n",
    "\n",
    "    for filename in os.listdir(folder_path)[:100]: #TODO limited # of images rn \n",
    "        if filename.endswith(\".png\"):\n",
    "            parts = filename.split('_')\n",
    "            fabType = parts[0]\n",
    "            id1 = parts[1]\n",
    "            id2 = parts[3].split('.')[0]  # Remove .png extension\n",
    "            \n",
    "            unique_id = id1 + id2\n",
    "\n",
    "            img = Image.open(os.path.join(folder_path, filename)).convert('L')\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            # normalize the image vector to be between 0 and 1\n",
    "            img_vector_normalized = img_array.flatten() / 255.0\n",
    "\n",
    "            ### SCALAR FEATURES ###\n",
    "            hog_stats = extract_hog_features(img_array, 4, 20)\n",
    "            hog_mean, hog_sum, hog_var, hog_skew, hog_kurt = hog_stats[:5]\n",
    "            wavelet_stats = extract_wavelet_features(img_array)\n",
    "            wave_mean_cA, wave_var_cA, wave_mean_cD, wave_var_cD = wavelet_stats[:4]\n",
    "            \n",
    "            scalar_features = []\n",
    "            scalar_features.extend([\n",
    "                            extract_log_features(img_array),    \n",
    "                            extract_normals_features(img_array), \n",
    "                            extract_gabor_features(img_array),\n",
    "                            hog_mean, hog_sum, hog_var, hog_skew, hog_kurt,\n",
    "                            wave_mean_cA, wave_var_cA, wave_mean_cD, wave_var_cD\n",
    "                            ])\n",
    "            \n",
    "            scalar_features_array = np.array(scalar_features)\n",
    "\n",
    "            \"\"\" TODO - Delete?? \n",
    "            ------>>>\n",
    "            # new_vector_with_scalar = np.append(img_vector_normalized, log_scalar)\n",
    "\n",
    "            ### VECTORIZED FEATURES ###\n",
    "            # log_vector = extract_log_features(img_array, scalar=False)\n",
    "            # hog_vector = extract_hog_features(img_array, 4, 20, scalar=False)\n",
    "            # normals_vector = extract_normals_features(img_array, scalar = False)\n",
    "            \n",
    "            #NOTE: This is created but then not used, I added as an additional output (features)  \n",
    "            # final_img_feature_vector  = np.concatenate((img_vector_normalized, scalar_features_array, log_vector, hog_vector, normals_vector)) # BE SURE TO ADD ANY FEATURE VECTORS HERE\n",
    "            <<<-----   \n",
    "            \"\"\"\n",
    "            final_img_feature_vector  = np.concatenate((img_vector_normalized, scalar_features_array)) # Scalars only \n",
    "\n",
    "            image_vectors.append(img_vector_normalized)\n",
    "            labels.append(fabType)\n",
    "            ids.append(unique_id)\n",
    "            features.append(final_img_feature_vector)\n",
    "\n",
    "    X = np.array(image_vectors)\n",
    "    Y = np.array(labels)\n",
    "    unique_ids = np.array(ids)\n",
    "    features_array = np.array(features)\n",
    "    return X, Y, unique_ids, features_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note - the cell below takes ~25 seconds to run on my mac. It may take a bit longer depending on your processing power and memory. If this becomes an issue, we can save the dataframe it creates as a pickle file, which could be saved to sub-samples and you two would be able to use without issue i.e. my computer processes and adds features and then saves it as a compressed python binary to allow for easy access that avoids double processing later. Just let me know if we need to do that!\n",
    "\n",
    "Note 2 - After adding HOG and Normals features, it took 4 m 4.2 sec in my computer, the second time broke, so I created a code that is only to create the df. The original one + the 2 additional features is in parse_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>39993</th>\n",
       "      <th>39994</th>\n",
       "      <th>39995</th>\n",
       "      <th>39996</th>\n",
       "      <th>39997</th>\n",
       "      <th>39998</th>\n",
       "      <th>39999</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.086275</td>\n",
       "      <td>0.101961</td>\n",
       "      <td>0.101961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>Blended</td>\n",
       "      <td>0</td>\n",
       "      <td>8821c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.258824</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.301961</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.478431</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.749020</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.760784</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>Denim</td>\n",
       "      <td>1</td>\n",
       "      <td>1503c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.258824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>Polyester</td>\n",
       "      <td>2</td>\n",
       "      <td>16132c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.364706</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>0.345098</td>\n",
       "      <td>0.341176</td>\n",
       "      <td>0.345098</td>\n",
       "      <td>0.388235</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.423529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.415686</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.505882</td>\n",
       "      <td>0.545098</td>\n",
       "      <td>Blended</td>\n",
       "      <td>0</td>\n",
       "      <td>3621d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.321569</td>\n",
       "      <td>0.317647</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.301961</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.325490</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376471</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>0.278431</td>\n",
       "      <td>0.345098</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>Cotton</td>\n",
       "      <td>3</td>\n",
       "      <td>2333a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40003 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.062745  0.058824  0.066667  0.062745  0.062745  0.066667  0.082353   \n",
       "1  0.266667  0.258824  0.270588  0.301961  0.313725  0.352941  0.439216   \n",
       "2  0.235294  0.247059  0.274510  0.298039  0.309804  0.305882  0.282353   \n",
       "3  0.380392  0.364706  0.356863  0.345098  0.341176  0.345098  0.388235   \n",
       "4  0.321569  0.317647  0.305882  0.298039  0.294118  0.301961  0.309804   \n",
       "\n",
       "          7         8         9  ...     39993     39994     39995     39996  \\\n",
       "0  0.086275  0.101961  0.101961  ...  0.066667  0.058824  0.054902  0.054902   \n",
       "1  0.478431  0.572549  0.607843  ...  0.200000  0.333333  0.749020  0.803922   \n",
       "2  0.274510  0.270588  0.258824  ...  0.168627  0.133333  0.125490  0.133333   \n",
       "3  0.435294  0.450980  0.423529  ...  0.400000  0.415686  0.450980  0.482353   \n",
       "4  0.313725  0.325490  0.333333  ...  0.376471  0.298039  0.247059  0.278431   \n",
       "\n",
       "      39997     39998     39999   category  label     uid  \n",
       "0  0.058824  0.062745  0.062745    Blended      0   8821c  \n",
       "1  0.788235  0.760784  0.717647      Denim      1   1503c  \n",
       "2  0.160784  0.192157  0.211765  Polyester      2  16132c  \n",
       "3  0.482353  0.505882  0.545098    Blended      0   3621d  \n",
       "4  0.345098  0.333333  0.309804     Cotton      3   2333a  \n",
       "\n",
       "[5 rows x 40003 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PARSE ALL \n",
    "folder_path = './Subsamples/train'\n",
    "X, Y, unique_ids, features_array = parse_all(folder_path)\n",
    "\n",
    "df = pd.DataFrame(X)\n",
    "df['category'] = pd.Categorical(Y)\n",
    "df['label'], _ = pd.factorize(df['category'])\n",
    "df['uid'] = unique_ids\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>39993</th>\n",
       "      <th>39994</th>\n",
       "      <th>39995</th>\n",
       "      <th>39996</th>\n",
       "      <th>39997</th>\n",
       "      <th>39998</th>\n",
       "      <th>39999</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.086275</td>\n",
       "      <td>0.101961</td>\n",
       "      <td>0.101961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>Blended</td>\n",
       "      <td>0</td>\n",
       "      <td>8821c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.258824</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.301961</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.478431</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.749020</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.760784</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>Denim</td>\n",
       "      <td>1</td>\n",
       "      <td>1503c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.258824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>Polyester</td>\n",
       "      <td>2</td>\n",
       "      <td>16132c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.364706</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>0.345098</td>\n",
       "      <td>0.341176</td>\n",
       "      <td>0.345098</td>\n",
       "      <td>0.388235</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.423529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.415686</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.505882</td>\n",
       "      <td>0.545098</td>\n",
       "      <td>Blended</td>\n",
       "      <td>0</td>\n",
       "      <td>3621d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.321569</td>\n",
       "      <td>0.317647</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.301961</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.325490</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376471</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>0.278431</td>\n",
       "      <td>0.345098</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>Cotton</td>\n",
       "      <td>3</td>\n",
       "      <td>2333a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40003 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.062745  0.058824  0.066667  0.062745  0.062745  0.066667  0.082353   \n",
       "1  0.266667  0.258824  0.270588  0.301961  0.313725  0.352941  0.439216   \n",
       "2  0.235294  0.247059  0.274510  0.298039  0.309804  0.305882  0.282353   \n",
       "3  0.380392  0.364706  0.356863  0.345098  0.341176  0.345098  0.388235   \n",
       "4  0.321569  0.317647  0.305882  0.298039  0.294118  0.301961  0.309804   \n",
       "\n",
       "          7         8         9  ...     39993     39994     39995     39996  \\\n",
       "0  0.086275  0.101961  0.101961  ...  0.066667  0.058824  0.054902  0.054902   \n",
       "1  0.478431  0.572549  0.607843  ...  0.200000  0.333333  0.749020  0.803922   \n",
       "2  0.274510  0.270588  0.258824  ...  0.168627  0.133333  0.125490  0.133333   \n",
       "3  0.435294  0.450980  0.423529  ...  0.400000  0.415686  0.450980  0.482353   \n",
       "4  0.313725  0.325490  0.333333  ...  0.376471  0.298039  0.247059  0.278431   \n",
       "\n",
       "      39997     39998     39999   category  label     uid  \n",
       "0  0.058824  0.062745  0.062745    Blended      0   8821c  \n",
       "1  0.788235  0.760784  0.717647      Denim      1   1503c  \n",
       "2  0.160784  0.192157  0.211765  Polyester      2  16132c  \n",
       "3  0.482353  0.505882  0.545098    Blended      0   3621d  \n",
       "4  0.345098  0.333333  0.309804     Cotton      3   2333a  \n",
       "\n",
       "[5 rows x 40003 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PARSE DATA \n",
    "folder_path = './Subsamples/train'\n",
    "X, Y, unique_ids = parse_data(folder_path)\n",
    "\n",
    "df = pd.DataFrame(X)\n",
    "df['category'] = pd.Categorical(Y)\n",
    "df['label'], _ = pd.factorize(df['category'])\n",
    "df['uid'] = unique_ids\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this dataframe, which is in the same format as the data shown in the MNIST D200 homework, it should be easy to set up t-SNE and PCA. HOWEVER - at this point we don't have any true features, as our existing features need to be converted to columns in this dataframe. Below is skeleton code that can be filled out to run and add these features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO - INSERT PCA AND OTHER EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>39990</th>\n",
       "      <th>39991</th>\n",
       "      <th>39992</th>\n",
       "      <th>39993</th>\n",
       "      <th>39994</th>\n",
       "      <th>39995</th>\n",
       "      <th>39996</th>\n",
       "      <th>39997</th>\n",
       "      <th>39998</th>\n",
       "      <th>39999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Blended</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.086275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086275</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.062745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Denim</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.258824</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.301961</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.478431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.749020</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.760784</td>\n",
       "      <td>0.717647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Polyester</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.211765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Blended</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.364706</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>0.345098</td>\n",
       "      <td>0.341176</td>\n",
       "      <td>0.345098</td>\n",
       "      <td>0.388235</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.415686</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.505882</td>\n",
       "      <td>0.545098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Cotton</td>\n",
       "      <td>0.321569</td>\n",
       "      <td>0.317647</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.301961</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.462745</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.376471</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>0.278431</td>\n",
       "      <td>0.345098</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.309804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label   category         0         1         2         3         4  \\\n",
       "0      0    Blended  0.062745  0.058824  0.066667  0.062745  0.062745   \n",
       "1      1      Denim  0.266667  0.258824  0.270588  0.301961  0.313725   \n",
       "2      2  Polyester  0.235294  0.247059  0.274510  0.298039  0.309804   \n",
       "3      0    Blended  0.380392  0.364706  0.356863  0.345098  0.341176   \n",
       "4      3     Cotton  0.321569  0.317647  0.305882  0.298039  0.294118   \n",
       "\n",
       "          5         6         7  ...     39990     39991     39992     39993  \\\n",
       "0  0.066667  0.082353  0.086275  ...  0.086275  0.082353  0.070588  0.066667   \n",
       "1  0.352941  0.439216  0.478431  ...  0.164706  0.149020  0.176471  0.200000   \n",
       "2  0.305882  0.282353  0.274510  ...  0.160784  0.180392  0.160784  0.168627   \n",
       "3  0.345098  0.388235  0.435294  ...  0.270588  0.270588  0.305882  0.400000   \n",
       "4  0.301961  0.309804  0.313725  ...  0.576471  0.462745  0.411765  0.376471   \n",
       "\n",
       "      39994     39995     39996     39997     39998     39999  \n",
       "0  0.058824  0.054902  0.054902  0.058824  0.062745  0.062745  \n",
       "1  0.333333  0.749020  0.803922  0.788235  0.760784  0.717647  \n",
       "2  0.133333  0.125490  0.133333  0.160784  0.192157  0.211765  \n",
       "3  0.415686  0.450980  0.482353  0.482353  0.505882  0.545098  \n",
       "4  0.298039  0.247059  0.278431  0.345098  0.333333  0.309804  \n",
       "\n",
       "[5 rows x 40002 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reorder \n",
    "train_df = df\n",
    "train_df.columns = train_df.columns.astype(str)\n",
    "PIXEL_COLS = train_df.columns.tolist()[:-3] # list of pixel header\n",
    "LABEL_COLS = ['label', 'category'] # list of labels header\n",
    "\n",
    "cols_reorder = LABEL_COLS + PIXEL_COLS\n",
    "train_df = train_df[cols_reorder]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose  a sample of the data to see if works:\n",
    "# Sample data\n",
    "sampled_train_df = train_df.sample(frac=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>39990</th>\n",
       "      <th>39991</th>\n",
       "      <th>39992</th>\n",
       "      <th>39993</th>\n",
       "      <th>39994</th>\n",
       "      <th>39995</th>\n",
       "      <th>39996</th>\n",
       "      <th>39997</th>\n",
       "      <th>39998</th>\n",
       "      <th>39999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20691</th>\n",
       "      <td>4</td>\n",
       "      <td>Wool</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.972549</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.984314</td>\n",
       "      <td>0.984314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.721569</td>\n",
       "      <td>0.701961</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.611765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10644</th>\n",
       "      <td>4</td>\n",
       "      <td>Wool</td>\n",
       "      <td>0.368627</td>\n",
       "      <td>0.368627</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.349020</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>0.321569</td>\n",
       "      <td>0.278431</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.278431</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10333</th>\n",
       "      <td>2</td>\n",
       "      <td>Polyester</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.560784</td>\n",
       "      <td>0.556863</td>\n",
       "      <td>0.513725</td>\n",
       "      <td>0.474510</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.498039</td>\n",
       "      <td>0.525490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454902</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>0.443137</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.443137</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.474510</td>\n",
       "      <td>0.490196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10858</th>\n",
       "      <td>1</td>\n",
       "      <td>Denim</td>\n",
       "      <td>0.145098</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.086275</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.219608</td>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.239216</td>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.227451</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.180392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9757</th>\n",
       "      <td>0</td>\n",
       "      <td>Blended</td>\n",
       "      <td>0.415686</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.423529</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.423529</td>\n",
       "      <td>0.360784</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.462745</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.474510</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.505882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9619</th>\n",
       "      <td>4</td>\n",
       "      <td>Wool</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.074510</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.074510</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556863</td>\n",
       "      <td>0.454902</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.184314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10101</th>\n",
       "      <td>3</td>\n",
       "      <td>Cotton</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.796078</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.713725</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>0.737255</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.772549</td>\n",
       "      <td>0.807843</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6574</th>\n",
       "      <td>1</td>\n",
       "      <td>Denim</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.388235</td>\n",
       "      <td>0.360784</td>\n",
       "      <td>0.368627</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.423529</td>\n",
       "      <td>0.443137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.603922</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.435294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8549</th>\n",
       "      <td>3</td>\n",
       "      <td>Cotton</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.090196</td>\n",
       "      <td>0.086275</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.090196</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>0.145098</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.160784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16511</th>\n",
       "      <td>1</td>\n",
       "      <td>Denim</td>\n",
       "      <td>0.498039</td>\n",
       "      <td>0.505882</td>\n",
       "      <td>0.513725</td>\n",
       "      <td>0.513725</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>0.423529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.301961</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.364706</td>\n",
       "      <td>0.388235</td>\n",
       "      <td>0.427451</td>\n",
       "      <td>0.427451</td>\n",
       "      <td>0.407843</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.396078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4426 rows × 40002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label   category         0         1         2         3         4  \\\n",
       "20691      4       Wool  0.976471  0.976471  0.972549  0.976471  0.976471   \n",
       "10644      4       Wool  0.368627  0.368627  0.333333  0.309804  0.313725   \n",
       "10333      2  Polyester  0.568627  0.560784  0.556863  0.513725  0.474510   \n",
       "10858      1      Denim  0.145098  0.133333  0.086275  0.070588  0.066667   \n",
       "9757       0    Blended  0.415686  0.411765  0.423529  0.435294  0.423529   \n",
       "...      ...        ...       ...       ...       ...       ...       ...   \n",
       "9619       4       Wool  0.125490  0.094118  0.070588  0.070588  0.074510   \n",
       "10101      3     Cotton  0.800000  0.803922  0.796078  0.792157  0.792157   \n",
       "6574       1      Denim  0.470588  0.450980  0.388235  0.360784  0.368627   \n",
       "8549       3     Cotton  0.113725  0.090196  0.086275  0.078431  0.090196   \n",
       "16511      1      Denim  0.498039  0.505882  0.513725  0.513725  0.517647   \n",
       "\n",
       "              5         6         7  ...     39990     39991     39992  \\\n",
       "20691  0.980392  0.984314  0.984314  ...  0.764706  0.741176  0.721569   \n",
       "10644  0.349020  0.356863  0.329412  ...  0.356863  0.321569  0.278431   \n",
       "10333  0.470588  0.498039  0.525490  ...  0.454902  0.447059  0.443137   \n",
       "10858  0.062745  0.058824  0.058824  ...  0.188235  0.219608  0.231373   \n",
       "9757   0.360784  0.309804  0.298039  ...  0.462745  0.482353  0.482353   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "9619   0.078431  0.074510  0.082353  ...  0.556863  0.454902  0.372549   \n",
       "10101  0.792157  0.788235  0.792157  ...  0.729412  0.705882  0.713725   \n",
       "6574   0.392157  0.423529  0.443137  ...  0.431373  0.458824  0.490196   \n",
       "8549   0.105882  0.152941  0.125490  ...  0.164706  0.164706  0.164706   \n",
       "16511  0.482353  0.447059  0.423529  ...  0.301961  0.329412  0.352941   \n",
       "\n",
       "          39993     39994     39995     39996     39997     39998     39999  \n",
       "20691  0.701961  0.666667  0.635294  0.627451  0.611765  0.611765  0.611765  \n",
       "10644  0.266667  0.266667  0.274510  0.278431  0.294118  0.294118  0.294118  \n",
       "10333  0.439216  0.435294  0.431373  0.443137  0.450980  0.474510  0.490196  \n",
       "10858  0.231373  0.239216  0.231373  0.231373  0.227451  0.196078  0.180392  \n",
       "9757   0.482353  0.490196  0.474510  0.470588  0.447059  0.494118  0.505882  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "9619   0.337255  0.262745  0.184314  0.160784  0.149020  0.160784  0.184314  \n",
       "10101  0.717647  0.737255  0.764706  0.772549  0.807843  0.858824  0.882353  \n",
       "6574   0.568627  0.694118  0.603922  0.552941  0.490196  0.439216  0.435294  \n",
       "8549   0.160784  0.152941  0.156863  0.149020  0.145098  0.156863  0.160784  \n",
       "16511  0.364706  0.388235  0.427451  0.427451  0.407843  0.411765  0.396078  \n",
       "\n",
       "[4426 rows x 40002 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA (From data 200 code, lecture-26) - This is too heavy to run\n",
    "n_comps = 100\n",
    "PCA_COLS = [f\"pc{i+1}\" for i in range(n_comps)]\n",
    "pca = PCA(n_components=n_comps)\n",
    "pca.fit(sampled_train_df[PIXEL_COLS])\n",
    "principal_components = pca.transform(sampled_train_df[PIXEL_COLS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9055491486444824"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8421972428877974"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PC1, PC2 component scores\n",
    "np.sum(pca.explained_variance_ratio_[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "variances = pca.explained_variance_ratio_\n",
    "\n",
    "cumulatives = [] \n",
    "\n",
    "for i in range(len(variances)):\n",
    "    if i == 0:\n",
    "        cumulative = variances[i]  # For the first element, cumulative sum is the variance itself\n",
    "    else:\n",
    "        cumulative += variances[i]  # Accumulate the current variance to the previous cumulative sum\n",
    "    cumulatives.append(cumulative)\n",
    "\n",
    "cumulatives\n",
    "# plot the explained variance (here we have to do it in the opposite side)\n",
    "plt.plot(np.arange(n_comps)+1,\n",
    "         cumulatives,\n",
    "         marker='.');\n",
    "plt.ylabel(\"% variance\")\n",
    "plt.xlabel(\"Component Number\")\n",
    "plt.title(\"Variance Explained by each Component\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA (From data 200 code, lecture-26) - This is too heavy to run\n",
    "n_comps = 20\n",
    "PCA_COLS = [f\"pc{i+1}\" for i in range(n_comps)]\n",
    "pca2 = PCA(n_components=n_comps)\n",
    "pca2.fit(train_df[PIXEL_COLS])\n",
    "principal_components_2 = pca2.transform(train_df[PIXEL_COLS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "variances = pca2.explained_variance_ratio_\n",
    "\n",
    "cumulatives = [] \n",
    "\n",
    "for i in range(len(variances)):\n",
    "    if i == 0:\n",
    "        cumulative = variances[i]  # For the first element, cumulative sum is the variance itself\n",
    "    else:\n",
    "        cumulative += variances[i]  # Accumulate the current variance to the previous cumulative sum\n",
    "    cumulatives.append(cumulative)\n",
    "\n",
    "cumulatives\n",
    "# plot the explained variance (here we have to do it in the opposite side)\n",
    "plt.plot(np.arange(n_comps)+1,\n",
    "         cumulatives,\n",
    "         marker='.');\n",
    "plt.ylabel(\"% variance\")\n",
    "plt.xlabel(\"Component Number\")\n",
    "plt.title(\"Variance Explained by each Component\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_scalar(folder_path):\n",
    "    scalars = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".png\"):\n",
    "            img = Image.open(os.path.join(folder_path, filename)).convert('L')\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            ### SCALAR FEATURES ###\n",
    "            hog_stats = extract_hog_features(img_array, 4, 20)\n",
    "            hog_mean, hog_sum, hog_var, hog_skew, hog_kurt = hog_stats[:5]\n",
    "            wavelet_stats = extract_wavelet_features(img_array)\n",
    "            wave_mean_cA, wave_var_cA, wave_mean_cD, wave_var_cD = wavelet_stats[:4]\n",
    "            \n",
    "            scalar_features = []\n",
    "            scalar_features.extend([\n",
    "                            extract_log_features(img_array),    \n",
    "                            extract_normals_features(img_array), \n",
    "                            extract_gabor_features(img_array),\n",
    "                            hog_mean, hog_sum, hog_var, hog_skew, hog_kurt,\n",
    "                            wave_mean_cA, wave_var_cA, wave_mean_cD, wave_var_cD\n",
    "                            ])\n",
    "\n",
    "\n",
    "            scalars.append(scalar_features)\n",
    "    return scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = './Subsamples/train'\n",
    "scalars_features = extract_scalar(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4084582.0</td>\n",
       "      <td>848125.481865</td>\n",
       "      <td>250793.0</td>\n",
       "      <td>0.150290</td>\n",
       "      <td>346.268127</td>\n",
       "      <td>0.005191</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>188.70860</td>\n",
       "      <td>19587.608386</td>\n",
       "      <td>0.100800</td>\n",
       "      <td>66.292873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5083084.0</td>\n",
       "      <td>188153.935541</td>\n",
       "      <td>475839.0</td>\n",
       "      <td>0.151459</td>\n",
       "      <td>348.960510</td>\n",
       "      <td>0.004838</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>245.86870</td>\n",
       "      <td>10136.469710</td>\n",
       "      <td>-0.030100</td>\n",
       "      <td>118.415777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4591326.0</td>\n",
       "      <td>469947.845153</td>\n",
       "      <td>84792.0</td>\n",
       "      <td>0.160472</td>\n",
       "      <td>369.726685</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>92.02735</td>\n",
       "      <td>853.668027</td>\n",
       "      <td>0.030550</td>\n",
       "      <td>14.026042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4976703.0</td>\n",
       "      <td>353395.602580</td>\n",
       "      <td>216421.0</td>\n",
       "      <td>0.152294</td>\n",
       "      <td>350.886292</td>\n",
       "      <td>0.004584</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>242.57325</td>\n",
       "      <td>2894.154259</td>\n",
       "      <td>0.014783</td>\n",
       "      <td>30.088056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4834379.0</td>\n",
       "      <td>310404.673397</td>\n",
       "      <td>217692.0</td>\n",
       "      <td>0.157962</td>\n",
       "      <td>363.943604</td>\n",
       "      <td>0.002826</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>183.02350</td>\n",
       "      <td>2864.363798</td>\n",
       "      <td>-0.051767</td>\n",
       "      <td>40.247404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0              1         2         3           4         5   \\\n",
       "0  4084582.0  848125.481865  250793.0  0.150290  346.268127  0.005191   \n",
       "1  5083084.0  188153.935541  475839.0  0.151459  348.960510  0.004838   \n",
       "2  4591326.0  469947.845153   84792.0  0.160472  369.726685  0.002027   \n",
       "3  4976703.0  353395.602580  216421.0  0.152294  350.886292  0.004584   \n",
       "4  4834379.0  310404.673397  217692.0  0.157962  363.943604  0.002826   \n",
       "\n",
       "         6         7          8             9         10          11  \n",
       "0  0.000090  0.000063  188.70860  19587.608386  0.100800   66.292873  \n",
       "1 -0.000069  0.000038  245.86870  10136.469710 -0.030100  118.415777  \n",
       "2 -0.000002  0.000008   92.02735    853.668027  0.030550   14.026042  \n",
       "3  0.000015  0.000034  242.57325   2894.154259  0.014783   30.088056  \n",
       "4  0.000002  0.000017  183.02350   2864.363798 -0.051767   40.247404  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalars_array = np.array(scalars_features)\n",
    "scalars_df = pd.DataFrame(scalars_array)\n",
    "scalars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA over scalars features\n",
    "n_comps = 11\n",
    "pca_scalar = PCA(n_components=n_comps)\n",
    "pca_scalar.fit(scalars_df)\n",
    "principal_components_2 = pca_scalar.transform(scalars_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "variances = pca_scalar.explained_variance_ratio_\n",
    "\n",
    "cumulatives = [] \n",
    "\n",
    "for i in range(len(variances)):\n",
    "    if i == 0:\n",
    "        cumulative = variances[i]  # For the first element, cumulative sum is the variance itself\n",
    "    else:\n",
    "        cumulative += variances[i]  # Accumulate the current variance to the previous cumulative sum\n",
    "    cumulatives.append(cumulative)\n",
    "\n",
    "cumulatives\n",
    "# plot the explained variance (here we have to do it in the opposite side)\n",
    "plt.plot(np.arange(n_comps)+1,\n",
    "         cumulatives,\n",
    "         marker='.');\n",
    "plt.ylabel(\"% variance\")\n",
    "plt.xlabel(\"Component Number\")\n",
    "plt.title(\"Variance Explained by Scalar Component\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - Multi-Class Classifier\n",
    "\n",
    "\n",
    "The function below takes in a test DF, features (which we can modified in the event we have thousands of columns and they are named numerically -- in this case we just need to drop the target variable to define X). It runs cross validation to determine the best hyperparameters to be used for the support vector machine model, returning a grid search object with the following attributes (per ChatGPT):\n",
    "\n",
    "<b>Attributes</b>\n",
    "* best_estimator_: The estimator that was chosen by the search, i.e., the estimator which gave highest score (or smallest loss if specified) on the left out data. Not available if refit=False.\n",
    "* best_score_: The score of the best_estimator on the left out data.\n",
    "* best_params_: The parameter setting that gave the best results on the hold out data.\n",
    "* best_index_: The index (of the cv_results_ arrays) which corresponds to the best candidate parameter setting.\n",
    "* cv_results_: A dictionary with keys as column headers and values as columns, that can be imported into a pandas DataFrame. This attribute provides scores, fit times, score times, and parameters for all the candidate models. It contains a lot of detailed information for each parameter combination that was evaluated.\n",
    "* scorer_: The function or a dictionary of functions that scores the predictions on the test set.\n",
    "* n_splits_: The number of cross-validation splits (folds/iterations).\n",
    "* refit_time_: Time for refitting the best estimator on the whole dataset (available only if refit is set to True).\n",
    "\n",
    "<b>Methods</b>\n",
    "* fit(X, y=None, groups=None): Run fit with all sets of parameters.\n",
    "* predict(X): Call predict on the estimator with the best found parameters.\n",
    "* score(X, y=None): Returns the score on the given data, if the estimator has been refit.\n",
    "* predict_proba(X): Call predict_proba on the estimator with the best found parameters, if available.\n",
    "* decision_function(X): Call decision_function on the estimator with the best found parameters, if available.\n",
    "* transform(X): Call transform on the estimator with the best found parameters, if available.\n",
    "* inverse_transform(X): Call inverse_transform on the estimator with the best found parameters, if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_grid_search_cv(dataframe, features, target, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Perform grid search cross-validation for SVM classifier on the given dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataframe: The pandas DataFrame containing the dataset.\n",
    "    - features: List of column names to be used as features.\n",
    "    - target: The name of the column to be used as the target variable.\n",
    "    - cv_folds: Number of folds for cross-validation.\n",
    "    \n",
    "    Returns:\n",
    "    - grid_search: The fitted GridSearchCV object.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Separate the features and the target variable\n",
    "    X = dataframe[features]\n",
    "    y = dataframe[target]\n",
    "    \n",
    "    # Split the data into training and testing sets (optional, could also perform CV on the entire dataset)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Define a pipeline that includes scaling and the classifier\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),  # Feature scaling is important for SVM\n",
    "        ('svm', SVC(probability=True))  # SVM classifier\n",
    "    ])\n",
    "    \n",
    "    # Parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'svm__C': [0.1, 1, 10],  # SVM regularization parameter\n",
    "        'svm__kernel': ['linear', 'rbf'],  # Kernel type to be used in the algorithm\n",
    "        'svm__gamma': ['scale', 'auto']  # Kernel coefficient for 'rbf', 'poly' and 'sigmoid'\n",
    "    }\n",
    "    \n",
    "    # Initialize GridSearchCV\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=cv_folds, scoring='accuracy', verbose=1)\n",
    "    \n",
    "    # Perform grid search cross-validation\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best parameters found: \", grid_search.best_params_)\n",
    "    print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "    \n",
    "    # Optionally, evaluate on the test set\n",
    "    test_score = grid_search.score(X_test, y_test)\n",
    "    print(\"Test set score: {:.2f}\".format(test_score))\n",
    "    \n",
    "    return grid_search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network\n",
    "\n",
    "The below code has not been tested or debugged - it was read through against a TDS article for accuracy, but it would need significant work, change in approach (and potentially additional compute) if we are to make it work. I wanted to store it so I don't lose the information though!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple cnn model\n",
    "# def create_cnn_model(input_shape, num_classes):\n",
    "#     model = models.Sequential([\n",
    "#         # convolutional layer with ReLU activation and Max Pooling\n",
    "#         layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "#         layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "#         # convolutional layer 2\n",
    "#         layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "#         layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "#         # flatten the output and add dense layers for classification\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(64, activation='relu'),\n",
    "#         layers.Dense(num_classes, activation='softmax')\n",
    "#     ])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# input_shape = (64, 64, 3)  # input shape (height, width, channels)\n",
    "# num_classes = 5\n",
    "\n",
    "# model = create_cnn_model(input_shape, num_classes)\n",
    "\n",
    "# # compile the model\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='sparse_categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# # train_images, train_labels = ... \n",
    "# # val_images, val_labels = ... \n",
    "\n",
    "# train model\n",
    "# history = model.fit(train_images, train_labels, epochs=10, validation_data=(val_images, val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO - ADD SVM CODE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
