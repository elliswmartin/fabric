{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ! pip install tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "np.random.seed(23)\n",
    "plt.rcParams['figure.figsize'] = (4, 4)\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO \n",
    "\n",
    "We really need to create functions that take in an image array and spit out a single feature value that could be added to a vector (I also want to talk to the professor about whether this is the most effective way to do this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_log_features(image_array, sigma=0.7, scalar=True):\n",
    "    \"\"\"\n",
    "    Extract Laplacian of Gaussian (LoG) features from an image array.\n",
    "    \n",
    "    Parameters:\n",
    "        image_array (numpy.ndarray): The input image array.\n",
    "        sigma (float): The sigma value for the Gaussian filter. Controls the amount of smoothing.\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: The LoG filtered image as a feature vector.\n",
    "    \"\"\"\n",
    "    # Apply the Laplacian of Gaussian filter\n",
    "    log_image = ndimage.gaussian_laplace(image_array, sigma=sigma)\n",
    "\n",
    "    if scalar:\n",
    "        \n",
    "        # OPTION 1\n",
    "        \n",
    "        # feature scalar: the sum of absolute values in the LoG image (a simple measure of edginess)\n",
    "        feature_scalar = np.sum(np.abs(log_image))\n",
    "\n",
    "        return feature_scalar\n",
    "\n",
    "    else:\n",
    "        # OPTION 2\n",
    "        \n",
    "        # feature vector: flatten the LoG image to use as a feature vector directly\n",
    "        feature_vector = log_image.flatten()\n",
    "\n",
    "        return feature_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In essence, each image needs to be represented as a feature vector. In the D200 example, the photos of the clothing items were in grayscale and then normalized and then reshaped using `train_images_vectors = np.reshape(train_images, (len(train_images), -1))` where train images is an array of n 28 x 28 training images (i.e. train_images.shape = (n, 28, 28)). After each image is reshaped, the vector is 1 x 784 (i.e. 28 x 28).\n",
    "\n",
    "We need a dataframe at the end of the day, where each row represents an image and its features. I want to talk more about which features we are actually going to leverage and use as a team, but for right now, I will build the plumbing to be able to run a classification once we actually have the features using the 'full image' technique employed in D200. In our case the images are still 200 x 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(folder_path):\n",
    "    image_vectors = []  # image data\n",
    "    labels = []  # labels\n",
    "    ids = []  # unique IDs\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".png\"):\n",
    "            parts = filename.split('_')\n",
    "            fabType = parts[0]\n",
    "            id1 = parts[1]\n",
    "            id2 = parts[3].split('.')[0]  # Remove .png extension\n",
    "            \n",
    "            unique_id = id1 + id2\n",
    "\n",
    "            img = Image.open(os.path.join(folder_path, filename)).convert('L')\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            # normalize the image vector to be between 0 and 1\n",
    "            img_vector_normalized = img_array.flatten() / 255.0\n",
    "\n",
    "            log_scalar = extract_log_features(img_array)\n",
    "            new_vector_with_scalar = np.append(img_vector_normalized, log_scalar)\n",
    "\n",
    "            #### TO DO - MAJOR ####\n",
    "            #### ADD FEATURES IN HERE #####\n",
    "            \n",
    "            image_vectors.append(img_vector_normalized)\n",
    "            labels.append(fabType)\n",
    "            ids.append(unique_id)\n",
    "\n",
    "    X = np.array(image_vectors)\n",
    "    Y = np.array(labels)\n",
    "    unique_ids = np.array(ids)\n",
    "    return X, Y, unique_ids   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note - the cell below takes ~25 seconds to run on my mac. It may take a bit longer depending on your processing power and memory. If this becomes an issue, we can save the dataframe it creates as a pickle file, which could be saved to sub-samples and you two would be able to use without issue i.e. my computer processes and adds features and then saves it as a compressed python binary to allow for easy access that avoids double processing later. Just let me know if we need to do that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>39993</th>\n",
       "      <th>39994</th>\n",
       "      <th>39995</th>\n",
       "      <th>39996</th>\n",
       "      <th>39997</th>\n",
       "      <th>39998</th>\n",
       "      <th>39999</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.086275</td>\n",
       "      <td>0.101961</td>\n",
       "      <td>0.101961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>Blended</td>\n",
       "      <td>0</td>\n",
       "      <td>8821c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.258824</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.301961</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.478431</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.749020</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.760784</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>Denim</td>\n",
       "      <td>1</td>\n",
       "      <td>1503c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.258824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>Polyester</td>\n",
       "      <td>2</td>\n",
       "      <td>16132c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.364706</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>0.345098</td>\n",
       "      <td>0.341176</td>\n",
       "      <td>0.345098</td>\n",
       "      <td>0.388235</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.423529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.415686</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.505882</td>\n",
       "      <td>0.545098</td>\n",
       "      <td>Blended</td>\n",
       "      <td>0</td>\n",
       "      <td>3621d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.321569</td>\n",
       "      <td>0.317647</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.301961</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.325490</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376471</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>0.278431</td>\n",
       "      <td>0.345098</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>Cotton</td>\n",
       "      <td>3</td>\n",
       "      <td>2333a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40003 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.062745  0.058824  0.066667  0.062745  0.062745  0.066667  0.082353   \n",
       "1  0.266667  0.258824  0.270588  0.301961  0.313725  0.352941  0.439216   \n",
       "2  0.235294  0.247059  0.274510  0.298039  0.309804  0.305882  0.282353   \n",
       "3  0.380392  0.364706  0.356863  0.345098  0.341176  0.345098  0.388235   \n",
       "4  0.321569  0.317647  0.305882  0.298039  0.294118  0.301961  0.309804   \n",
       "\n",
       "          7         8         9  ...     39993     39994     39995     39996  \\\n",
       "0  0.086275  0.101961  0.101961  ...  0.066667  0.058824  0.054902  0.054902   \n",
       "1  0.478431  0.572549  0.607843  ...  0.200000  0.333333  0.749020  0.803922   \n",
       "2  0.274510  0.270588  0.258824  ...  0.168627  0.133333  0.125490  0.133333   \n",
       "3  0.435294  0.450980  0.423529  ...  0.400000  0.415686  0.450980  0.482353   \n",
       "4  0.313725  0.325490  0.333333  ...  0.376471  0.298039  0.247059  0.278431   \n",
       "\n",
       "      39997     39998     39999   category  label     uid  \n",
       "0  0.058824  0.062745  0.062745    Blended      0   8821c  \n",
       "1  0.788235  0.760784  0.717647      Denim      1   1503c  \n",
       "2  0.160784  0.192157  0.211765  Polyester      2  16132c  \n",
       "3  0.482353  0.505882  0.545098    Blended      0   3621d  \n",
       "4  0.345098  0.333333  0.309804     Cotton      3   2333a  \n",
       "\n",
       "[5 rows x 40003 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = './Subsamples/train'\n",
    "X, Y, unique_ids = parse_data(folder_path)\n",
    "\n",
    "df = pd.DataFrame(X)\n",
    "df['category'] = pd.Categorical(Y)\n",
    "df['label'], _ = pd.factorize(df['category'])\n",
    "df['uid'] = unique_ids\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this dataframe, which is in the same format as the data shown in the MNIST D200 homework, it should be easy to set up t-SNE and PCA. HOWEVER - at this point we don't have any true features, as our existing features need to be converted to columns in this dataframe. Below is skeleton code that can be filled out to run and add these features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO - INSERT PCA AND OTHER EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training/validation split\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple cnn model\n",
    "# def create_cnn_model(input_shape, num_classes):\n",
    "#     model = models.Sequential([\n",
    "#         # convolutional layer with ReLU activation and Max Pooling\n",
    "#         layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "#         layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "#         # convolutional layer 2\n",
    "#         layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "#         layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "#         # flatten the output and add dense layers for classification\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(64, activation='relu'),\n",
    "#         layers.Dense(num_classes, activation='softmax')\n",
    "#     ])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# input_shape = (64, 64, 3)  # input shape (height, width, channels)\n",
    "# num_classes = 5\n",
    "\n",
    "# model = create_cnn_model(input_shape, num_classes)\n",
    "\n",
    "# # compile the model\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='sparse_categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# # train_images, train_labels = ... \n",
    "# # val_images, val_labels = ... \n",
    "\n",
    "# train model\n",
    "# history = model.fit(train_images, train_labels, epochs=10, validation_data=(val_images, val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO - ADD SVM CODE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tanlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
