{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - Multi-Class Classifier\n",
    "\n",
    "\n",
    "The function below takes in a test DF, features (which we can modified in the event we have thousands of columns and they are named numerically -- in this case we just need to drop the target variable to define X). It runs cross validation to determine the best hyperparameters to be used for the support vector machine model, returning a grid search object with the following attributes (per ChatGPT):\n",
    "\n",
    "<b>Attributes</b>\n",
    "* best_estimator_: The estimator that was chosen by the search, i.e., the estimator which gave highest score (or smallest loss if specified) on the left out data. Not available if refit=False.\n",
    "* best_score_: The score of the best_estimator on the left out data.\n",
    "* best_params_: The parameter setting that gave the best results on the hold out data.\n",
    "* best_index_: The index (of the cv_results_ arrays) which corresponds to the best candidate parameter setting.\n",
    "* cv_results_: A dictionary with keys as column headers and values as columns, that can be imported into a pandas DataFrame. This attribute provides scores, fit times, score times, and parameters for all the candidate models. It contains a lot of detailed information for each parameter combination that was evaluated.\n",
    "* scorer_: The function or a dictionary of functions that scores the predictions on the test set.\n",
    "* n_splits_: The number of cross-validation splits (folds/iterations).\n",
    "* refit_time_: Time for refitting the best estimator on the whole dataset (available only if refit is set to True).\n",
    "\n",
    "<b>Methods</b>\n",
    "* fit(X, y=None, groups=None): Run fit with all sets of parameters.\n",
    "* predict(X): Call predict on the estimator with the best found parameters.\n",
    "* score(X, y=None): Returns the score on the given data, if the estimator has been refit.\n",
    "* predict_proba(X): Call predict_proba on the estimator with the best found parameters, if available.\n",
    "* decision_function(X): Call decision_function on the estimator with the best found parameters, if available.\n",
    "* transform(X): Call transform on the estimator with the best found parameters, if available.\n",
    "* inverse_transform(X): Call inverse_transform on the estimator with the best found parameters, if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_grid_search_cv(dataframe, features, target, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Perform grid search cross-validation for SVM classifier on the given dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataframe: The pandas DataFrame containing the dataset.\n",
    "    - features: List of column names to be used as features.\n",
    "    - target: The name of the column to be used as the target variable.\n",
    "    - cv_folds: Number of folds for cross-validation.\n",
    "    \n",
    "    Returns:\n",
    "    - grid_search: The fitted GridSearchCV object.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Separate the features and the target variable\n",
    "    X = dataframe[features]\n",
    "    y = dataframe[target]\n",
    "    \n",
    "    # Split the data into training and testing sets (optional, could also perform CV on the entire dataset)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Define a pipeline that includes scaling and the classifier\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),  # Feature scaling is important for SVM\n",
    "        ('svm', SVC(probability=True))  # SVM classifier\n",
    "    ])\n",
    "    \n",
    "    # Parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'svm__C': [0.1, 1, 10],  # SVM regularization parameter\n",
    "        'svm__kernel': ['linear', 'rbf'],  # Kernel type to be used in the algorithm\n",
    "        'svm__gamma': ['scale', 'auto']  # Kernel coefficient for 'rbf', 'poly' and 'sigmoid'\n",
    "    }\n",
    "    \n",
    "    # Initialize GridSearchCV\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=cv_folds, scoring='accuracy', verbose=1)\n",
    "    \n",
    "    # Perform grid search cross-validation\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best parameters found: \", grid_search.best_params_)\n",
    "    print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "    \n",
    "    # Optionally, evaluate on the test set\n",
    "    test_score = grid_search.score(X_test, y_test)\n",
    "    print(\"Test set score: {:.2f}\".format(test_score))\n",
    "    \n",
    "    return grid_search"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
